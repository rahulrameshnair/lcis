{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "text = \"saf-lh2-dlr\"\n",
    "gen_uuid = uuid.uuid5(uuid.NAMESPACE_X500, text)\n",
    "print(gen_uuid)\n",
    "print(str(gen_uuid).replace('-',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "dateandtime = datetime.now(timezone.utc)\n",
    "formatted_timestamp = dateandtime.strftime(\"%Y%m%d-%H%M%S\")\n",
    "print (dateandtime)\n",
    "print (formatted_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from datetime import datetime, timezone\n",
    "dataset_name = \"saf-lh2-dlr\"\n",
    "schema_version = \"LCI2024\"\n",
    "dataset_version = \"1.0.2\"\n",
    "#schema_version = input (\"Enter the Schema version (e.g. LCIS2024): \")\n",
    "#dataset_version = input (\"Enter the version of the Dataset (e.g 1.0.1): \")\n",
    "text_for_udi = dataset_name + \"_\" + schema_version + \"_\" + dataset_version\n",
    "print(text_for_udi)\n",
    "\n",
    "def identifying_info (dataset_name, schema_version, dataset_version):\n",
    "    timestamp = datetime.now(timezone.utc)\n",
    "    dataset_time = timestamp.strftime(\"%Y%m%d-%H%M%S\") #formatting the time of the dataset in the form of yyyymmdd-hhmmss\n",
    "    text_for_udi = dataset_name + schema_version + dataset_version + dataset_time\n",
    "    udi = uuid.uuid5(uuid.NAMESPACE_X500, text_for_udi) #creates an unique dataset identifier (UDI)\n",
    "    dataset_udi = str(udi).replace('-','') #removes the - in the generated unique dataset identifier\n",
    "    idf_props = {\"Dataset name\": dataset_name, \"Schema version\": schema_version, \"Dataset version\": dataset_version, \"Export time\": dataset_time, \"UDI\": dataset_udi}\n",
    "    return (idf_props)\n",
    "print (identifying_info(dataset_name, schema_version, dataset_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lol = {\n",
    "    \"key1\": \"value1\",\n",
    "    \"key2\": \"value2\",\n",
    "    \"key3\": \"value3\"\n",
    "}\n",
    "\n",
    "gol = {\n",
    "    \"keyA\": \"valueA\",\n",
    "    \"keyB\": \"valueB\",\n",
    "    \"keyC\": \"valueC\"\n",
    "}\n",
    "\n",
    "print(lol | gol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brightway2\n",
    "version = brightway2.__version__\n",
    "\n",
    "bw_version = \"Brightway \" + '.'.join(map(str, version))\n",
    "print(bw_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTuple(tup):\n",
    "    str = ''.join(str (num) for num in tuple)\n",
    "    return str\n",
    " \n",
    " \n",
    "# Driver code\n",
    "tuple = (1, 2, 3)\n",
    "str = convertTuple(tuple)\n",
    "print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_of_numbers = (1, 9, 24)\n",
    "joined_string = '.'.join(map(str, tuple_of_numbers))\n",
    "print(joined_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print (os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bw2data as bw\n",
    "bw.projects.set_current(\"stagingbw2\")\n",
    "selected_database = bw.Database(\"Fuelcellstack\")\n",
    "database_dependencies = []\n",
    "for activity in selected_database:\n",
    "    for exchange in activity.exchanges():\n",
    "        if 'database' in exchange:\n",
    "            db_value = exchange['database']\n",
    "            if db_value not in database_dependencies:\n",
    "                database_dependencies.append(db_value)\n",
    "print (\"Dependent Databases are: \", database_dependencies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_excel_to_csv(excel_file_path, csv_file_path):\n",
    "    \"\"\"\n",
    "    Convert the metadata Excel file to a CSV (comma separated) form using pandas.\n",
    "\n",
    "    Parameters:\n",
    "    excel_file_path (str): The path to the source Excel file.\n",
    "    csv_file_path (str): The path where the CSV file will be saved.\n",
    "    \"\"\"\n",
    "    # Read the Excel file\n",
    "    df = pd.read_excel(excel_file_path)\n",
    "    # Save the dataframe to a CSV file\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    print(f\"File converted and saved as {csv_file_path}\")\n",
    "excel_file_path = input(\"Enter the path to the Excel metadata file: \")\n",
    "csv_file_path = input(\"Enter the path to the csv metadata file: \")\n",
    "convert_excel_to_csv(excel_file_path, csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.1\n"
     ]
    }
   ],
   "source": [
    "from export.libs import __version__\n",
    "print(__version__)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
